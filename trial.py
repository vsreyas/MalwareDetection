import numpy as np
import pcaper
import os
import pandas as pd

directory = "http"
parent_dir = "/home/venky/Documents/IITM Dec/Malware detection using N Grams and SVM"
path = os.path.join(parent_dir, directory)

pcap_parser = pcaper.PcapParser()
params = {
    'input': '/home/venky/Documents/IITM Dec/Malware detection using N Grams and SVM/MalDetHTTP/data_p/http1.pcap',
}

i = 0

for request in pcap_parser.read_pcap(params):
    print(request)
    dest = os.path.join(path,'http'+str(i)+'.txt')
    f = open(dest,'w')
    f.write(request.origin)
    f.close()
    i = i + 1

tot_req = i
os.mkdir(path)

for i in range(tot_req):
    inp = os.path.join(path,'http'+str(i)+'.txt')
    f = open(inp,'r')
    dest = os.path.join(path,'http_o'+str(i)+'.txt')
    f1 = open(dest,'w')
   
    counter = str('')
    for each in f:
        curr = each
        print(each, str(1))
        rep = [',',';',':','/','?','=','(',')','{','}','the','is','were','  ']
        for r in rep:
            curr = curr.replace(r,' ')
        common = ['.jpg','.png','.gif','.js','.css']
        new = curr.split()
        for check in common:
            for word in new:
                k = word.find(check)
                if k >= 0: new.remove(word)
        
        new.append('\n')
        new = ' '.join(new)
        counter = counter + new
        f1.write(new)
    counter = counter.split()
    df = pd.value_counts(np.array(counter), normalize=True)
    count = df.T.to_dict()
    c = os.path.join(path,'http_c'+str(i)+'.csv')
    df.to_csv(c)
    f.close()
    f1.close()

    

    

        